{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8accd-f46f-4992-81c8-b0c47532507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset_tool import compute_loudness, compute_centroid\n",
    "from IPython.display import Audio\n",
    "import pickle\n",
    "import librosa as li\n",
    "from noisebandnet.model import NoiseBandNet\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf071d-7e72-4dc3-9d2a-e3007aa2dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, fs, max_len, norm=True):\n",
    "    x = li.load(path, sr=fs, mono=True)[0]\n",
    "    if max_len > 0:\n",
    "        if len(x)>max_len:\n",
    "            x = x[:max_len]\n",
    "    if norm:\n",
    "        x = li.util.normalize(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36393c9-ad5e-4e50-aa71-36d6fdd13a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "TRAIN_PATH = 'trained_models/metal'\n",
    "MODEL_PATH = f'{TRAIN_PATH}/model_10000.ckpt'\n",
    "CONFIG_PATH = f'{TRAIN_PATH}/config.pickle'\n",
    "\n",
    "#path to the training data used to train de model\n",
    "AUDIO_PATH = 'training_data/metal.wav'\n",
    "\n",
    "with (open(CONFIG_PATH, \"rb\")) as f:\n",
    "    config = pickle.load(f)\n",
    "FS = config.sampling_rate\n",
    "\n",
    "x_audio = load_audio(path=AUDIO_PATH, fs=FS, max_len=2**19)\n",
    "x_audio = torch.from_numpy(x_audio).unsqueeze(0)\n",
    "Audio(x_audio[0], rate=FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c3e8c-4ccb-46a8-9c10-9a1e1d4bdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This example works for models trained with loudness or loudness and centroid.\n",
    "# For user-defined control parameters you need to load them manually.\n",
    "if len(config.auto_control_params) != 2:\n",
    "    if config.auto_control_params == \"loudness\":\n",
    "        loudness, _, _ = compute_loudness(audio_data=x_audio, sampling_rate=FS)\n",
    "        loudness = loudness.unsqueeze(0).float()\n",
    "        loudness = F.interpolate(input=loudness, scale_factor=1/config.synth_window, mode='linear').permute(0,2,1).float()\n",
    "        control_params = [loudness.to(device)]\n",
    "    if config.auto_control_params == \"centroid\":\n",
    "        centroid, _, _ = compute_centroid(audio_data=x_audio, sampling_rate=FS)\n",
    "        centroid = centroid.unsqueeze(0).float()\n",
    "        centroid = F.interpolate(input=centroid, scale_factor=1/config.synth_window, mode='linear').permute(0,2,1).float()\n",
    "        control_params = [centroid.to(device)]\n",
    "else:\n",
    "    control_params = []\n",
    "    loudness, _, _ = compute_loudness(audio_data=x_audio, sampling_rate=FS)\n",
    "    loudness = loudness.unsqueeze(0).float()\n",
    "    loudness = F.interpolate(input=loudness, scale_factor=1/config.synth_window, mode='linear').permute(0,2,1).float()\n",
    "    control_params.append(loudness)\n",
    "    \n",
    "    centroid, _, _ = compute_centroid(audio_data=x_audio, sampling_rate=FS)\n",
    "    centroid = centroid.unsqueeze(0).float()\n",
    "    centroid = F.interpolate(input=centroid, scale_factor=1/config.synth_window, mode='linear').permute(0,2,1).float()\n",
    "    control_params.append(centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45007b4-79f9-4343-8001-f25609b9358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = NoiseBandNet(hidden_size=config.hidden_size, n_band=config.n_band, synth_window=config.synth_window, n_control_params=config.n_control_params).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6344609-43ad-4b84-b950-f403b63ce24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d7552-ceec-49e0-9c5e-af1564c58ba8",
   "metadata": {},
   "source": [
    "## Stereo generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9bc1f-2d23-4c21-9e9e-c779b1742b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_audio = []\n",
    "for i in range(2):\n",
    "    with torch.no_grad():\n",
    "        y_audio.append(synth.forward_random(control_params=control_params, frame_len=control_params[0].shape[1], frequency_shifts=0, k_amplitudes=10, k_low_mult=0.95, k_high_mult=1.15, init_f_shifts=0))\n",
    "y_audio = torch.cat(y_audio).permute(1,0,2)\n",
    "Audio(y_audio[0].detach().cpu().numpy(), rate=FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96499a87-6d59-4282-ab03-a44db603d878",
   "metadata": {},
   "source": [
    "## Amplitude randomisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf13efa-f29b-494d-aedb-7348147085b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_len = control_params[0].shape[1]\n",
    "audio_chunks = 2\n",
    "frame_len = audio_len//audio_chunks\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_audio = synth.forward_random(control_params=control_params, frame_len=frame_len, frequency_shifts=1, k_amplitudes=100, k_low_mult=0., k_high_mult=1., init_f_shifts=10)\n",
    "Audio(y_audio[0].detach().cpu().numpy(), rate=FS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
